{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "import time\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wavio\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_list = ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537\n",
      "68\n",
      "68\n",
      "*****0*****\n",
      "1573\n",
      "68\n",
      "68\n",
      "*****1*****\n",
      "1567\n",
      "68\n",
      "68\n",
      "*****2*****\n",
      "1566\n",
      "68\n",
      "68\n",
      "*****3*****\n",
      "2106\n",
      "68\n",
      "68\n",
      "*****4*****\n",
      "2095\n",
      "68\n",
      "68\n",
      "*****5*****\n",
      "2086\n",
      "68\n",
      "68\n",
      "*****6*****\n",
      "2119\n",
      "68\n",
      "68\n",
      "*****7*****\n",
      "2121\n",
      "68\n",
      "68\n",
      "*****8*****\n",
      "1562\n",
      "68\n",
      "68\n",
      "*****9*****\n",
      "1600\n",
      "68\n",
      "68\n",
      "*****10*****\n",
      "2086\n",
      "68\n",
      "68\n",
      "*****11*****\n",
      "1584\n",
      "68\n",
      "68\n",
      "*****12*****\n",
      "2105\n",
      "68\n",
      "68\n",
      "*****13*****\n",
      "2123\n",
      "68\n",
      "68\n",
      "*****14*****\n",
      "2095\n",
      "68\n",
      "68\n",
      "*****15*****\n",
      "2121\n",
      "68\n",
      "68\n",
      "*****16*****\n",
      "2122\n",
      "68\n",
      "68\n",
      "*****17*****\n",
      "2108\n",
      "68\n",
      "68\n",
      "*****18*****\n",
      "2138\n",
      "68\n",
      "68\n",
      "*****19*****\n",
      "1548\n",
      "68\n",
      "68\n",
      "*****20*****\n",
      "2125\n",
      "68\n",
      "68\n",
      "*****21*****\n",
      "2131\n",
      "68\n",
      "68\n",
      "*****22*****\n",
      "2089\n",
      "68\n",
      "68\n",
      "*****23*****\n",
      "1540\n",
      "68\n",
      "68\n",
      "*****24*****\n",
      "2109\n",
      "68\n",
      "68\n",
      "*****25*****\n",
      "2103\n",
      "68\n",
      "68\n",
      "*****26*****\n",
      "1580\n",
      "68\n",
      "68\n",
      "*****27*****\n",
      "2121\n",
      "68\n",
      "68\n",
      "*****28*****\n",
      "2126\n",
      "68\n",
      "68\n",
      "*****29*****\n"
     ]
    }
   ],
   "source": [
    "y=[]\n",
    "X_train = []\n",
    "for i in range(30):\n",
    "    filePath = \"D:\\\\ccf2020\\\\%s\" % filename_list[i]\n",
    "    fl = os.listdir(filePath)\n",
    "    print(len(fl))\n",
    "    for j in range(len(fl)):\n",
    "        wavpath = filePath + '\\\\' + fl[j]\n",
    "        sig,sr = librosa.load(wavpath)\n",
    "        y.append(int(i))\n",
    "        #print(len(sig))\n",
    "        temp = []\n",
    "        #过零率\n",
    "        a = librosa.feature.zero_crossing_rate(sig,sr)\n",
    "        b = np.mean(a)\n",
    "        temp.append(b)\n",
    "        #光谱质心\n",
    "        a = librosa.feature.spectral_centroid(sig,sr=sr)[0]\n",
    "        b = np.mean(a)\n",
    "        temp.append(b)\n",
    "        #MFCC\n",
    "        a = librosa.feature.mfcc(sig,sr,n_mfcc=40)\n",
    "        b = np.mean(a,axis = 1)\n",
    "        for k in range(len(b)):\n",
    "            temp.append(b[k])\n",
    "        #色度频谱\n",
    "        a = librosa.feature.chroma_stft(sig,sr)\n",
    "        b = np.mean(a,axis = 1)\n",
    "        for k in range(len(b)):\n",
    "            temp.append(b[k])\n",
    "        #谱对比度\n",
    "        a = librosa.feature.spectral_contrast(sig,sr)\n",
    "        b = np.mean(a,axis = 1)\n",
    "        for k in range(len(b)):\n",
    "            temp.append(b[k]) \n",
    "        #频谱带宽\n",
    "        a = librosa.feature.spectral_bandwidth(sig,sr)\n",
    "        b = np.mean(a,axis=1)\n",
    "        temp.append(b)\n",
    "        #tonnetz\n",
    "        a = librosa.feature.tonnetz(sig,sr)\n",
    "        b = np.mean(a,axis = 1)\n",
    "        for k in range(len(b)):\n",
    "            temp.append(b[k])\n",
    "        if j < 2:\n",
    "            print(len(temp))\n",
    "        X_train.append(temp)\n",
    "    print('*****%s*****'%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6835\n",
      "68\n",
      "68\n",
      "68\n",
      "68\n",
      "68\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "filePath = \"D:\\\\ccf2020\\\\test\"\n",
    "fl = os.listdir(filePath)\n",
    "print(len(fl))\n",
    "\n",
    "for j in range(len(fl)):\n",
    "    wavpath = filePath + '\\\\' + fl[j]\n",
    "    sig,sr = librosa.load(wavpath)\n",
    "    #print(len(sig))\n",
    "    temp = []\n",
    "    #过零率\n",
    "    a = librosa.feature.zero_crossing_rate(sig,sr)\n",
    "    b = np.mean(a)\n",
    "    temp.append(b)\n",
    "    #光谱质心\n",
    "    a = librosa.feature.spectral_centroid(sig,sr=sr)[0]\n",
    "    b = np.mean(a)\n",
    "    temp.append(b)\n",
    "    #MFCC\n",
    "    a = librosa.feature.mfcc(sig,sr,n_mfcc=40)\n",
    "    b = np.mean(a,axis = 1)\n",
    "    for k in range(len(b)):\n",
    "        temp.append(b[k])\n",
    "    #色度频谱\n",
    "    a = librosa.feature.chroma_stft(sig,sr)\n",
    "    b = np.mean(a,axis = 1)\n",
    "    for k in range(len(b)):\n",
    "        temp.append(b[k])\n",
    "    #谱对比度\n",
    "    a = librosa.feature.spectral_contrast(sig,sr)\n",
    "    b = np.mean(a,axis = 1)\n",
    "    for k in range(len(b)):\n",
    "        temp.append(b[k]) \n",
    "    #频谱带宽\n",
    "    a = librosa.feature.spectral_bandwidth(sig,sr)\n",
    "    b = np.mean(a,axis=1)\n",
    "    temp.append(b)\n",
    "    #tonnetz\n",
    "    a = librosa.feature.tonnetz(sig,sr)\n",
    "    b = np.mean(a,axis = 1)\n",
    "    for k in range(len(b)):\n",
    "        temp.append(b[k])\n",
    "\n",
    "    if j<=5:\n",
    "        print(len(temp))\n",
    "    X_test.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57886, 68)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_c = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6835, 68)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train_c = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57886,)\n"
     ]
    }
   ],
   "source": [
    "print(y1_train_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['003gtit8kw.wav', '006irl4pgx.wav', '007sh75o5w.wav', '009k6j5dbw.wav', '009lyahcx8.wav', '00ajqu80u0.wav', '00xs1x0xu4.wav', '00zipjvjsy.wav', '01154zpb2g.wav', '016hhb0ofw.wav']\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "filePath = \"D:\\\\ccf2020\\\\test\"\n",
    "fl = os.listdir(filePath)\n",
    "print(fl[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfold = 5\n",
    "kf = KFold(n_splits=nfold, shuffle=True, random_state=2020)\n",
    "oof = np.zeros((len(X_train_c), ))\n",
    "prediction1 = np.zeros((len(X_test_c),30 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17340\n",
      "[LightGBM] [Info] Number of data points in the train set: 46308, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score -3.625865\n",
      "[LightGBM] [Info] Start training from score -3.618592\n",
      "[LightGBM] [Info] Start training from score -3.599452\n",
      "[LightGBM] [Info] Start training from score -3.616983\n",
      "[LightGBM] [Info] Start training from score -3.298237\n",
      "[LightGBM] [Info] Start training from score -3.316521\n",
      "[LightGBM] [Info] Start training from score -3.335752\n",
      "[LightGBM] [Info] Start training from score -3.313549\n",
      "[LightGBM] [Info] Start training from score -3.320696\n",
      "[LightGBM] [Info] Start training from score -3.602617\n",
      "[LightGBM] [Info] Start training from score -3.579898\n",
      "[LightGBM] [Info] Start training from score -3.327895\n",
      "[LightGBM] [Info] Start training from score -3.574490\n",
      "[LightGBM] [Info] Start training from score -3.312363\n",
      "[LightGBM] [Info] Start training from score -3.305864\n",
      "[LightGBM] [Info] Start training from score -3.319502\n",
      "[LightGBM] [Info] Start training from score -3.308222\n",
      "[LightGBM] [Info] Start training from score -3.310586\n",
      "[LightGBM] [Info] Start training from score -3.306453\n",
      "[LightGBM] [Info] Start training from score -3.297069\n",
      "[LightGBM] [Info] Start training from score -3.617787\n",
      "[LightGBM] [Info] Start training from score -3.300577\n",
      "[LightGBM] [Info] Start training from score -3.314737\n",
      "[LightGBM] [Info] Start training from score -3.317116\n",
      "[LightGBM] [Info] Start training from score -3.626676\n",
      "[LightGBM] [Info] Start training from score -3.307632\n",
      "[LightGBM] [Info] Start training from score -3.305864\n",
      "[LightGBM] [Info] Start training from score -3.614574\n",
      "[LightGBM] [Info] Start training from score -3.305864\n",
      "[LightGBM] [Info] Start training from score -3.317712\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's multi_logloss: 0.204423\tvalid_1's multi_logloss: 1.86806\n",
      "Early stopping, best iteration is:\n",
      "[668]\ttraining's multi_logloss: 0.0994219\tvalid_1's multi_logloss: 1.85437\n",
      "\n",
      "Fold 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17340\n",
      "[LightGBM] [Info] Number of data points in the train set: 46309, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score -3.631579\n",
      "[LightGBM] [Info] Start training from score -3.594746\n",
      "[LightGBM] [Info] Start training from score -3.603431\n",
      "[LightGBM] [Info] Start training from score -3.613794\n",
      "[LightGBM] [Info] Start training from score -3.303532\n",
      "[LightGBM] [Info] Start training from score -3.319523\n",
      "[LightGBM] [Info] Start training from score -3.311200\n",
      "[LightGBM] [Info] Start training from score -3.301185\n",
      "[LightGBM] [Info] Start training from score -3.301771\n",
      "[LightGBM] [Info] Start training from score -3.617809\n",
      "[LightGBM] [Info] Start training from score -3.590040\n",
      "[LightGBM] [Info] Start training from score -3.331535\n",
      "[LightGBM] [Info] Start training from score -3.604225\n",
      "[LightGBM] [Info] Start training from score -3.311792\n",
      "[LightGBM] [Info] Start training from score -3.318330\n",
      "[LightGBM] [Info] Start training from score -3.318330\n",
      "[LightGBM] [Info] Start training from score -3.302358\n",
      "[LightGBM] [Info] Start training from score -3.292431\n",
      "[LightGBM] [Info] Start training from score -3.328519\n",
      "[LightGBM] [Info] Start training from score -3.300013\n",
      "[LightGBM] [Info] Start training from score -3.614596\n",
      "[LightGBM] [Info] Start training from score -3.333955\n",
      "[LightGBM] [Info] Start training from score -3.300013\n",
      "[LightGBM] [Info] Start training from score -3.315947\n",
      "[LightGBM] [Info] Start training from score -3.609796\n",
      "[LightGBM] [Info] Start training from score -3.315947\n",
      "[LightGBM] [Info] Start training from score -3.320120\n",
      "[LightGBM] [Info] Start training from score -3.601846\n",
      "[LightGBM] [Info] Start training from score -3.308834\n",
      "[LightGBM] [Info] Start training from score -3.302945\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's multi_logloss: 0.204856\tvalid_1's multi_logloss: 1.86297\n",
      "Early stopping, best iteration is:\n",
      "[800]\ttraining's multi_logloss: 0.0588804\tvalid_1's multi_logloss: 1.84682\n",
      "\n",
      "Fold 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17340\n",
      "[LightGBM] [Info] Number of data points in the train set: 46309, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score -3.638948\n",
      "[LightGBM] [Info] Start training from score -3.620225\n",
      "[LightGBM] [Info] Start training from score -3.622647\n",
      "[LightGBM] [Info] Start training from score -3.603431\n",
      "[LightGBM] [Info] Start training from score -3.306474\n",
      "[LightGBM] [Info] Start training from score -3.307064\n",
      "[LightGBM] [Info] Start training from score -3.329724\n",
      "[LightGBM] [Info] Start training from score -3.291850\n",
      "[LightGBM] [Info] Start training from score -3.284905\n",
      "[LightGBM] [Info] Start training from score -3.616201\n",
      "[LightGBM] [Info] Start training from score -3.593175\n",
      "[LightGBM] [Info] Start training from score -3.349213\n",
      "[LightGBM] [Info] Start training from score -3.607404\n",
      "[LightGBM] [Info] Start training from score -3.321914\n",
      "[LightGBM] [Info] Start training from score -3.300599\n",
      "[LightGBM] [Info] Start training from score -3.310016\n",
      "[LightGBM] [Info] Start training from score -3.294176\n",
      "[LightGBM] [Info] Start training from score -3.305885\n",
      "[LightGBM] [Info] Start training from score -3.308244\n",
      "[LightGBM] [Info] Start training from score -3.303532\n",
      "[LightGBM] [Info] Start training from score -3.637305\n",
      "[LightGBM] [Info] Start training from score -3.290689\n",
      "[LightGBM] [Info] Start training from score -3.295340\n",
      "[LightGBM] [Info] Start training from score -3.321914\n",
      "[LightGBM] [Info] Start training from score -3.633212\n",
      "[LightGBM] [Info] Start training from score -3.318330\n",
      "[LightGBM] [Info] Start training from score -3.310016\n",
      "[LightGBM] [Info] Start training from score -3.618613\n",
      "[LightGBM] [Info] Start training from score -3.301771\n",
      "[LightGBM] [Info] Start training from score -3.307064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's multi_logloss: 0.204625\tvalid_1's multi_logloss: 1.88936\n",
      "Early stopping, best iteration is:\n",
      "[757]\ttraining's multi_logloss: 0.0696015\tvalid_1's multi_logloss: 1.87716\n",
      "\n",
      "Fold 4\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17340\n",
      "[LightGBM] [Info] Number of data points in the train set: 46309, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score -3.623456\n",
      "[LightGBM] [Info] Start training from score -3.598684\n",
      "[LightGBM] [Info] Start training from score -3.609796\n",
      "[LightGBM] [Info] Start training from score -3.626697\n",
      "[LightGBM] [Info] Start training from score -3.327315\n",
      "[LightGBM] [Info] Start training from score -3.318330\n",
      "[LightGBM] [Info] Start training from score -3.319523\n",
      "[LightGBM] [Info] Start training from score -3.326713\n",
      "[LightGBM] [Info] Start training from score -3.294758\n",
      "[LightGBM] [Info] Start training from score -3.616201\n",
      "[LightGBM] [Info] Start training from score -3.584578\n",
      "[LightGBM] [Info] Start training from score -3.295923\n",
      "[LightGBM] [Info] Start training from score -3.625075\n",
      "[LightGBM] [Info] Start training from score -3.307064\n",
      "[LightGBM] [Info] Start training from score -3.302358\n",
      "[LightGBM] [Info] Start training from score -3.320120\n",
      "[LightGBM] [Info] Start training from score -3.304120\n",
      "[LightGBM] [Info] Start training from score -3.306474\n",
      "[LightGBM] [Info] Start training from score -3.307654\n",
      "[LightGBM] [Info] Start training from score -3.288372\n",
      "[LightGBM] [Info] Start training from score -3.593960\n",
      "[LightGBM] [Info] Start training from score -3.298843\n",
      "[LightGBM] [Info] Start training from score -3.311200\n",
      "[LightGBM] [Info] Start training from score -3.330931\n",
      "[LightGBM] [Info] Start training from score -3.647198\n",
      "[LightGBM] [Info] Start training from score -3.314758\n",
      "[LightGBM] [Info] Start training from score -3.317138\n",
      "[LightGBM] [Info] Start training from score -3.606608\n",
      "[LightGBM] [Info] Start training from score -3.318926\n",
      "[LightGBM] [Info] Start training from score -3.291269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's multi_logloss: 0.202135\tvalid_1's multi_logloss: 1.87991\n",
      "Early stopping, best iteration is:\n",
      "[656]\ttraining's multi_logloss: 0.103574\tvalid_1's multi_logloss: 1.87188\n",
      "\n",
      "Fold 5\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17340\n",
      "[LightGBM] [Info] Number of data points in the train set: 46309, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score -3.623456\n",
      "[LightGBM] [Info] Start training from score -3.595532\n",
      "[LightGBM] [Info] Start training from score -3.611393\n",
      "[LightGBM] [Info] Start training from score -3.589258\n",
      "[LightGBM] [Info] Start training from score -3.333350\n",
      "[LightGBM] [Info] Start training from score -3.333350\n",
      "[LightGBM] [Info] Start training from score -3.320120\n",
      "[LightGBM] [Info] Start training from score -3.304708\n",
      "[LightGBM] [Info] Start training from score -3.331535\n",
      "[LightGBM] [Info] Start training from score -3.609796\n",
      "[LightGBM] [Info] Start training from score -3.594746\n",
      "[LightGBM] [Info] Start training from score -3.312385\n",
      "[LightGBM] [Info] Start training from score -3.582246\n",
      "[LightGBM] [Info] Start training from score -3.317734\n",
      "[LightGBM] [Info] Start training from score -3.301185\n",
      "[LightGBM] [Info] Start training from score -3.326713\n",
      "[LightGBM] [Info] Start training from score -3.324311\n",
      "[LightGBM] [Info] Start training from score -3.315353\n",
      "[LightGBM] [Info] Start training from score -3.312977\n",
      "[LightGBM] [Info] Start training from score -3.304120\n",
      "[LightGBM] [Info] Start training from score -3.644716\n",
      "[LightGBM] [Info] Start training from score -3.300013\n",
      "[LightGBM] [Info] Start training from score -3.288372\n",
      "[LightGBM] [Info] Start training from score -3.323112\n",
      "[LightGBM] [Info] Start training from score -3.617004\n",
      "[LightGBM] [Info] Start training from score -3.304708\n",
      "[LightGBM] [Info] Start training from score -3.322513\n",
      "[LightGBM] [Info] Start training from score -3.564546\n",
      "[LightGBM] [Info] Start training from score -3.297674\n",
      "[LightGBM] [Info] Start training from score -3.302358\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's multi_logloss: 0.204614\tvalid_1's multi_logloss: 1.87442\n",
      "Early stopping, best iteration is:\n",
      "[742]\ttraining's multi_logloss: 0.0732117\tvalid_1's multi_logloss: 1.85685\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 100000\n",
    "EARLY_STOP = 100\n",
    "VERBOSE = 500\n",
    "\n",
    "i = 0\n",
    "for train_index, valid_index in kf.split(X_train_c, y1_train_c):\n",
    "    print(\"\\nFold {}\".format(i + 1))\n",
    "    X_train, label_train = X_train_c[train_index],y1_train_c[train_index]\n",
    "    X_valid, label_valid = X_train_c[valid_index],y1_train_c[valid_index]\n",
    "    \n",
    "    params = {'num_leaves': 16, #结果对最终效果影响较大，越大值越好，太大会出现过拟合\n",
    "              'min_data_in_leaf': 16,\n",
    "              'objective': 'multiclass', #定义的目标函数\n",
    "              'is_unbalance' : True,\n",
    "              'max_depth': 8,\n",
    "              'learning_rate': 0.08,\n",
    "              'boosting': 'gbdt',\n",
    "              'feature_fraction': 0.98,  #提取的特征比率\n",
    "              'bagging_freq': 4,\n",
    "              'bagging_fraction': 0.8,\n",
    "              'lambda_l1': 0.1,             #l1正则\n",
    "              'lambda_l2': 0.2,     #l2正则\n",
    "              'num_class':30,\n",
    "              \"random_state\": 2020, #随机数种子，可以防止每次运行的结果不一致\n",
    "              }\n",
    "    trn_data = lgb.Dataset(X_train, label_train)\n",
    "    val_data = lgb.Dataset(X_valid, label_valid)\n",
    "    \n",
    "    clf = lgb.train(params,\n",
    "                    trn_data,\n",
    "                    30000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=VERBOSE,\n",
    "                    early_stopping_rounds=EARLY_STOP)\n",
    "\n",
    "    x1 = clf.predict(X_valid)\n",
    "    y1 = clf.predict(X_test_c)\n",
    "    prediction1 += ((y1)) / nfold\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01449035 0.00027185 0.00182696 0.00044376 0.04093012 0.00420515\n",
      " 0.00448687 0.01241846 0.00309413 0.14061745 0.00038459 0.010098\n",
      " 0.04452591 0.15516719 0.03899894 0.00119805 0.05393239 0.04556806\n",
      " 0.1515222  0.0102623  0.00158036 0.0010757  0.00773553 0.08058271\n",
      " 0.00142303 0.08520389 0.00296378 0.00042951 0.02139069 0.06317206]\n"
     ]
    }
   ],
   "source": [
    "print(prediction1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(prediction1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[list(x).index(max(x)) for x in prediction1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 28, 0, 5, 12, 20, 22, 26, 5, 18, 15, 29, 20, 6, 4, 10, 18, 18, 27, 17, 0, 4, 2, 18, 4, 22, 25, 5, 14, 21, 24, 23, 1, 25, 21, 1, 26, 22, 21, 23, 8, 29, 17, 17, 19, 18, 13, 18, 13, 0, 18, 28, 2, 29, 21, 6, 12, 19, 26, 26, 14, 21, 27, 12, 0, 5, 12, 14, 6, 6, 25, 9, 12, 18, 16, 18, 6, 13, 11, 2, 6, 19, 18, 18, 11, 17, 14, 25, 2, 23, 16, 22, 5, 23, 4, 13, 12, 6, 18, 3, 25, 26, 12, 25, 8, 26, 16, 5, 22, 24, 8, 24, 26, 29, 24, 24, 29, 24, 25, 20, 13, 19, 8, 20, 3, 11, 23, 18, 20, 7, 28, 22, 5, 7, 21, 6, 5, 28, 21, 28, 6, 29, 5, 29, 5, 15, 9, 28, 3, 28, 17, 4, 18, 15, 24, 13, 28, 24, 26, 11, 27, 6, 21, 14, 11, 16, 10, 25, 17, 14, 11, 18, 29, 26, 8, 28, 26, 21, 13, 18, 13, 5, 14, 18, 0, 19, 7, 12, 28, 24, 19, 11, 29, 20, 9, 13, 11, 18, 22, 29, 22, 17, 18, 11, 20, 25, 29, 11, 11, 11, 14, 19, 11, 24, 15, 18, 17, 29, 22, 1, 8, 26, 2, 14, 14, 1, 3, 17, 14, 20, 28, 22, 9, 8, 19, 23, 20, 5, 28, 24, 3, 18, 26, 6, 14, 11, 18, 4, 19, 28, 16, 14, 6, 13, 9, 20, 15, 21, 7, 25, 7, 5, 23, 23, 2, 15, 26, 28, 19, 18, 12, 6, 24, 27, 23, 0, 13, 18, 20, 21, 23, 10, 13, 19, 6, 6, 20, 6, 4, 18, 29, 13, 16, 7, 8, 29, 19, 19, 5, 26, 9, 22, 25, 6, 19, 14, 6, 13, 6, 26, 1, 11, 24, 7, 7, 12, 14, 23, 28, 21, 18, 29, 26, 26, 29, 15, 25, 11, 10, 1, 2, 14, 21, 14, 9, 8, 22, 26, 22, 8, 6, 10, 13, 23, 22, 18, 19, 13, 24, 28, 8, 11, 20, 29, 9, 14, 12, 16, 3, 28, 27, 27, 6, 5, 18, 16, 1, 7, 10, 5, 6, 19, 20, 8, 25, 18, 0, 16, 12, 19, 16, 24, 21, 6, 14, 18, 17, 24, 29, 25, 13, 8, 17, 14, 29, 26, 18, 24, 19, 27, 23, 29, 29, 14, 7, 13, 4, 13, 6, 26, 9, 22, 14, 22, 19, 6, 9, 17, 13, 6, 14, 5, 16, 7, 1, 19, 8, 15, 14, 11, 24, 0, 18, 9, 26, 13, 15, 16, 29, 17, 23, 19, 6, 25, 28, 24, 8, 16, 25, 27, 17, 23, 13, 22, 23, 23, 13, 19, 4, 8, 22, 13, 27, 0, 21, 12, 6, 14, 23, 27, 20, 13, 18, 9, 21, 8, 28, 11, 17, 8, 15, 24, 14, 4, 14, 21, 18, 0, 0, 9, 24, 26, 22, 26, 14, 14, 21, 1, 10, 11, 11, 24, 28, 25, 14, 13, 4, 20, 22, 20, 8, 18, 6, 2, 2, 13, 16, 8, 22, 26, 26, 9, 5, 23, 27, 5, 23, 27, 18, 14, 20, 16, 17, 22, 14, 5, 21, 3, 11, 4, 25, 12, 20, 10, 24, 23, 14, 13, 26, 18, 13, 12, 16, 15, 7, 4, 0, 13, 5, 29, 17, 25, 14, 6, 14, 23, 11, 7, 25, 23, 17, 14, 0, 18, 8, 16, 5, 9, 17, 22, 28, 10, 21, 4, 21, 29, 11, 15, 28, 29, 23, 14, 17, 20, 15, 8, 28, 24, 11, 14, 5, 27, 11, 13, 2, 6, 18, 9, 28, 2, 4, 8, 10, 0, 26, 19, 7, 17, 17, 6, 13, 17, 23, 6, 14, 18, 28, 22, 24, 29, 5, 18, 13, 16, 9, 16, 7, 28, 6, 7, 18, 1, 5, 21, 13, 5, 25, 5, 14, 24, 2, 22, 18, 11, 11, 5, 18, 13, 20, 7, 5, 28, 21, 6, 11, 26, 26, 15, 3, 25, 5, 8, 0, 15, 0, 19, 15, 1, 28, 18, 28, 28, 5, 22, 0, 13, 6, 20, 28, 7, 2, 0, 11, 0, 7, 14, 27, 9, 25, 14, 27, 21, 15, 26, 12, 29, 8, 18, 18, 6, 19, 7, 1, 2, 7, 4, 19, 26, 11, 26, 5, 18, 21, 18, 13, 17, 21, 21, 19, 14, 18, 8, 27, 18, 22, 7, 5, 14, 26, 2, 22, 19, 10, 0, 18, 0, 14, 9, 14, 11, 21, 5, 20, 26, 5, 28, 19, 5, 14, 25, 13, 18, 14, 26, 13, 26, 26, 27, 23, 14, 28, 28, 21, 26, 22, 20, 26, 18, 27, 2, 21, 28, 8, 6, 19, 19, 13, 18, 26, 26, 11, 27, 18, 14, 28, 27, 13, 10, 12, 23, 13, 6, 4, 16, 6, 27, 5, 21, 9, 24, 13, 8, 7, 23, 9, 15, 3, 8, 27, 17, 1, 14, 19, 18, 29, 14, 5, 22, 28, 11, 26, 18, 15, 18, 26, 25, 14, 17, 19, 27, 4, 21, 14, 18, 13, 6, 6, 8, 29, 7, 29, 10, 29, 8, 14, 1, 16, 6, 1, 21, 7, 6, 23, 0, 11, 5, 15, 25, 6, 25, 5, 0, 11, 8, 23, 22, 26, 21, 10, 0, 26, 5, 23, 5, 18, 26, 9, 15, 12, 3, 9, 5, 10, 22, 11, 13, 5, 18, 15, 4, 12, 24, 5, 6, 22, 19, 19, 8, 18, 4, 1, 8, 19, 11, 16, 22, 5, 0, 25, 0, 26, 22, 28, 9, 21, 18, 6, 18, 29, 28, 10, 16, 26, 0, 15, 10, 7, 21, 24, 2, 20, 1, 5, 16, 2, 4, 17, 28, 16, 3, 0, 24, 17, 23, 6, 10, 28, 5, 16, 8, 19, 6, 11, 14, 25, 29, 25, 2, 3, 11, 3, 20, 14, 16, 23, 22, 26, 3, 23, 6, 16, 2, 16, 13, 13, 23, 11, 6, 13, 8, 5, 5, 4, 5, 16, 26, 26, 21, 19, 13, 7, 9, 27, 23, 28, 13, 2, 9, 22, 22, 21, 23, 13, 11, 0, 6, 13, 25, 14, 18, 28, 19, 5, 5, 7, 17, 20, 6, 19, 25, 16, 11, 13, 2, 26, 11, 25, 15, 25, 0, 12, 29, 6, 26, 17, 11, 0, 22, 6, 6, 17, 15, 6, 24, 14, 8, 24, 8, 22, 1, 7, 18, 1, 18, 5, 25, 14, 14, 25, 6, 2, 5, 7, 7, 16, 11, 14, 2, 27, 26, 5, 2, 7, 0, 29, 4, 27, 17, 26, 27, 26, 18, 21, 24, 7, 9, 27, 15, 14, 28, 8, 18, 24, 27, 22, 4, 14, 9, 13, 5, 26, 18, 20, 23, 8, 16, 23, 0, 7, 25, 29, 0, 20, 25, 18, 12, 8, 7, 0, 4, 16, 6, 27, 16, 26, 5, 15, 1, 10, 28, 9, 25, 5, 19, 15, 0, 16, 12, 27, 14, 29, 20, 7, 1, 5, 14, 13, 20, 4, 6, 14, 29, 8, 26, 28, 6, 25, 25, 26, 15, 14, 22, 8, 14, 8, 19, 14, 29, 20, 24, 28, 10, 14, 29, 26, 23, 27, 20, 21, 6, 24, 24, 4, 16, 22, 20, 5, 26, 11, 17, 29, 19, 11, 27, 0, 0, 22, 5, 28, 26, 8, 0, 12, 10, 8, 29, 28, 19, 11, 3, 25, 28, 18, 2, 0, 22, 29, 19, 24, 22, 0, 19, 26, 6, 23, 1, 7, 7, 1, 23, 11, 1, 7, 2, 24, 7, 14, 4, 28, 23, 7, 4, 28, 26, 19, 7, 7, 25, 3, 7, 0, 13, 16, 17, 21, 10, 21, 22, 9, 17, 18, 22, 22, 16, 27, 14, 9, 2, 7, 1, 26, 5, 24, 26, 28, 23, 4, 23, 5, 2, 5, 8, 27, 11, 3, 28, 4, 26, 23, 2, 9, 20, 23, 28, 4, 25, 29, 5, 10, 28, 17, 2, 6, 5, 24, 23, 12, 29, 8, 26, 29, 23, 12, 20, 2, 11, 10, 22, 24, 19, 7, 18, 6, 10, 13, 19, 18, 11, 16, 2, 8, 7, 28, 1, 2, 19, 22, 22, 6, 19, 8, 23, 27, 29, 24, 9, 13, 28, 18, 11, 6, 28, 7, 29, 28, 8, 2, 14, 9, 22, 16, 26, 4, 26, 14, 13, 5, 7, 14, 20, 10, 23, 28, 8, 5, 9, 18, 18, 10, 23, 11, 17, 28, 20, 17, 0, 15, 16, 6, 0, 23, 13, 14, 13, 2, 14, 11, 7, 12, 21, 20, 9, 28, 19, 26, 21, 4, 7, 6, 13, 7, 18, 2, 7, 17, 29, 26, 5, 3, 18, 8, 23, 11, 12, 27, 24, 1, 4, 20, 17, 14, 19, 18, 15, 29, 27, 13, 26, 11, 4, 5, 17, 17, 15, 19, 19, 26, 27, 0, 23, 9, 5, 29, 23, 1, 13, 29, 5, 19, 11, 29, 28, 5, 24, 24, 4, 17, 3, 14, 27, 13, 7, 5, 29, 1, 29, 19, 2, 8, 28, 16, 27, 27, 26, 14, 2, 19, 5, 15, 27, 19, 16, 29, 14, 22, 26, 21, 21, 29, 8, 20, 19, 1, 15, 22, 7, 29, 7, 10, 2, 3, 10, 22, 7, 11, 5, 19, 20, 27, 26, 23, 21, 20, 19, 26, 9, 27, 24, 27, 24, 26, 17, 14, 13, 18, 14, 0, 4, 11, 12, 0, 16, 26, 18, 10, 16, 1, 18, 28, 18, 28, 4, 8, 5, 11, 4, 14, 20, 10, 7, 10, 25, 24, 22, 15, 12, 21, 22, 11, 4, 17, 15, 2, 4, 6, 27, 17, 18, 13, 11, 23, 15, 15, 20, 5, 13, 13, 24, 4, 20, 15, 14, 17, 28, 12, 22, 7, 21, 26, 20, 6, 1, 5, 24, 13, 5, 10, 1, 11, 18, 21, 28, 7, 15, 4, 27, 29, 18, 7, 25, 7, 18, 23, 15, 6, 14, 8, 22, 29, 10, 17, 5, 1, 28, 18, 4, 15, 8, 2, 1, 5, 26, 7, 28, 29, 6, 1, 19, 7, 20, 6, 9, 22, 20, 8, 17, 6, 1, 15, 14, 22, 25, 14, 25, 17, 29, 11, 13, 20, 28, 11, 17, 14, 13, 19, 3, 15, 15, 13, 18, 5, 8, 2, 26, 18, 28, 21, 18, 1, 2, 29, 21, 10, 7, 12, 29, 7, 14, 19, 27, 26, 14, 0, 4, 26, 5, 28, 9, 19, 25, 16, 18, 0, 25, 23, 15, 8, 14, 26, 25, 0, 25, 16, 4, 8, 8, 10, 7, 2, 9, 28, 25, 7, 17, 11, 5, 21, 15, 5, 8, 21, 27, 22, 6, 25, 28, 7, 16, 14, 25, 22, 5, 1, 23, 25, 28, 13, 0, 9, 3, 27, 8, 13, 19, 20, 23, 11, 28, 12, 19, 7, 16, 3, 5, 2, 2, 20, 22, 7, 5, 5, 0, 18, 4, 9, 27, 5, 15, 14, 20, 25, 10, 2, 5, 17, 12, 16, 5, 5, 6, 0, 26, 20, 18, 18, 13, 25, 2, 2, 27, 22, 14, 14, 9, 17, 13, 21, 25, 12, 20, 19, 24, 23, 13, 23, 14, 7, 5, 18, 18, 14, 28, 21, 13, 18, 8, 7, 11, 2, 17, 5, 7, 5, 25, 14, 18, 14, 28, 20, 27, 9, 0, 20, 22, 15, 13, 5, 19, 19, 20, 11, 11, 0, 26, 22, 17, 18, 26, 26, 24, 14, 3, 25, 27, 6, 27, 12, 22, 17, 14, 20, 6, 23, 19, 13, 24, 15, 11, 11, 8, 15, 17, 25, 11, 14, 26, 0, 3, 14, 5, 1, 24, 5, 25, 2, 18, 17, 29, 20, 18, 18, 23, 26, 3, 1, 12, 15, 12, 12, 2, 10, 9, 2, 23, 28, 17, 12, 13, 12, 26, 28, 23, 22, 14, 6, 6, 6, 18, 5, 19, 3, 20, 13, 4, 6, 20, 24, 25, 5, 17, 29, 23, 29, 11, 21, 27, 25, 28, 18, 11, 19, 0, 26, 6, 7, 25, 0, 20, 13, 7, 0, 27, 8, 19, 13, 9, 11, 0, 19, 22, 25, 24, 28, 11, 7, 19, 18, 5, 0, 18, 20, 21, 21, 14, 24, 5, 21, 20, 10, 0, 25, 5, 9, 18, 12, 19, 17, 18, 6, 2, 20, 26, 8, 16, 21, 1, 28, 0, 4, 17, 25, 19, 27, 12, 26, 15, 16, 13, 7, 22, 6, 2, 16, 10, 27, 22, 16, 14, 2, 4, 29, 16, 13, 13, 20, 20, 23, 8, 7, 4, 4, 27, 26, 0, 18, 8, 4, 25, 22, 11, 17, 18, 18, 13, 13, 17, 5, 8, 14, 6, 20, 7, 25, 25, 21, 15, 27, 5, 11, 1, 22, 22, 13, 16, 4, 19, 23, 9, 23, 15, 22, 22, 19, 26, 14, 17, 16, 10, 11, 29, 15, 13, 26, 21, 7, 10, 29, 10, 3, 16, 16, 12, 11, 13, 0, 13, 5, 2, 26, 6, 29, 21, 18, 22, 17, 19, 25, 22, 23, 6, 27, 1, 2, 23, 8, 14, 11, 14, 8, 22, 17, 19, 8, 4, 28, 16, 28, 24, 17, 19, 20, 6, 15, 7, 18, 26, 3, 17, 26, 28, 28, 23, 29, 6, 8, 7, 29, 22, 20, 6, 5, 27, 22, 20, 1, 5, 26, 18, 5, 15, 28, 1, 7, 4, 29, 29, 28, 29, 3, 17, 19, 3, 20, 4, 10, 10, 20, 28, 17, 20, 1, 18, 18, 24, 22, 20, 29, 15, 17, 1, 18, 28, 21, 27, 13, 8, 17, 24, 25, 12, 18, 17, 21, 29, 19, 9, 18, 20, 7, 7, 14, 27, 5, 8, 11, 13, 23, 20, 7, 20, 0, 6, 24, 26, 4, 19, 24, 11, 22, 16, 6, 25, 2, 22, 29, 11, 18, 26, 26, 9, 5, 21, 22, 1, 20, 16, 7, 23, 19, 1, 6, 5, 26, 23, 22, 5, 9, 7, 1, 13, 0, 26, 11, 14, 5, 2, 16, 1, 21, 18, 24, 20, 22, 29, 19, 25, 2, 27, 0, 12, 11, 3, 7, 23, 15, 18, 18, 18, 16, 6, 14, 27, 6, 15, 15, 16, 13, 14, 25, 21, 23, 29, 23, 21, 29, 7, 28, 27, 4, 1, 25, 22, 0, 9, 23, 29, 17, 24, 20, 19, 17, 0, 17, 25, 3, 5, 26, 2, 17, 26, 18, 4, 23, 11, 29, 19, 8, 5, 0, 5, 9, 6, 6, 25, 23, 0, 26, 28, 9, 15, 21, 26, 18, 23, 20, 13, 1, 13, 24, 27, 13, 23, 5, 27, 26, 13, 23, 11, 28, 1, 24, 16, 4, 1, 20, 5, 11, 24, 22, 15, 16, 14, 3, 25, 16, 27, 8, 23, 15, 6, 14, 11, 0, 17, 11, 2, 22, 25, 7, 22, 22, 28, 29, 29, 8, 5, 18, 26, 25, 21, 11, 13, 25, 18, 13, 21, 4, 25, 17, 12, 6, 16, 13, 6, 12, 10, 13, 2, 24, 23, 3, 25, 21, 19, 14, 9, 4, 22, 13, 26, 22, 8, 7, 4, 6, 1, 4, 23, 19, 13, 6, 11, 18, 17, 13, 20, 8, 26, 22, 2, 21, 2, 7, 16, 15, 23, 14, 7, 19, 20, 11, 6, 0, 19, 13, 5, 12, 13, 16, 24, 11, 29, 24, 23, 6, 12, 7, 26, 22, 1, 8, 8, 15, 0, 8, 8, 13, 4, 9, 9, 14, 21, 12, 6, 14, 13, 21, 21, 18, 27, 7, 19, 13, 9, 5, 4, 22, 23, 13, 18, 29, 13, 9, 22, 6, 5, 28, 27, 29, 8, 29, 14, 10, 20, 28, 14, 29, 24, 22, 13, 13, 27, 11, 25, 3, 14, 5, 2, 28, 9, 28, 17, 21, 17, 23, 4, 18, 6, 17, 13, 21, 6, 25, 8, 6, 8, 13, 12, 5, 1, 25, 12, 6, 10, 1, 19, 13, 14, 23, 22, 21, 11, 7, 13, 29, 26, 13, 22, 10, 29, 4, 25, 29, 18, 12, 4, 13, 8, 22, 14, 23, 22, 22, 13, 6, 18, 5, 9, 6, 13, 15, 16, 5, 14, 18, 0, 29, 2, 28, 0, 17, 4, 1, 19, 14, 22, 26, 27, 26, 22, 19, 20, 6, 9, 19, 22, 11, 15, 14, 22, 23, 2, 9, 26, 29, 6, 7, 24, 9, 25, 11, 19, 29, 26, 25, 7, 9, 8, 27, 21, 16, 23, 6, 5, 10, 26, 8, 27, 13, 28, 6, 10, 22, 1, 20, 2, 22, 25, 28, 14, 17, 19, 27, 6, 22, 8, 24, 0, 25, 6, 8, 6, 19, 17, 29, 11, 24, 0, 19, 12, 17, 15, 5, 29, 15, 9, 18, 16, 8, 6, 24, 16, 8, 4, 13, 20, 28, 24, 21, 7, 4, 4, 6, 14, 25, 20, 11, 3, 22, 5, 0, 29, 17, 23, 0, 28, 23, 1, 5, 22, 28, 21, 25, 1, 0, 14, 7, 26, 27, 11, 17, 28, 6, 12, 5, 28, 9, 8, 24, 0, 28, 3, 24, 9, 26, 13, 8, 25, 29, 26, 19, 5, 5, 8, 11, 2, 26, 19, 29, 13, 5, 28, 14, 5, 28, 15, 27, 4, 3, 26, 0, 5, 24, 23, 7, 1, 2, 24, 8, 0, 6, 22, 25, 18, 27, 10, 8, 18, 12, 21, 7, 29, 6, 29, 6, 9, 23, 19, 23, 25, 0, 16, 6, 5, 24, 26, 8, 6, 23, 3, 6, 19, 9, 5, 6, 7, 8, 8, 25, 17, 15, 3, 13, 13, 19, 9, 11, 18, 11, 3, 6, 13, 5, 6, 27, 15, 10, 8, 24, 5, 25, 11, 7, 29, 5, 8, 19, 15, 5, 28, 26, 14, 19, 5, 18, 18, 19, 6, 16, 6, 25, 12, 24, 2, 29, 28, 9, 6, 10, 24, 28, 26, 18, 7, 29, 2, 5, 24, 19, 20, 13, 17, 28, 29, 13, 8, 27, 0, 1, 22, 5, 2, 23, 0, 5, 14, 7, 28, 8, 11, 6, 29, 16, 9, 15, 28, 26, 25, 27, 26, 15, 18, 18, 16, 19, 5, 15, 6, 5, 4, 18, 18, 2, 4, 11, 24, 28, 13, 29, 18, 17, 29, 10, 12, 25, 22, 20, 29, 6, 17, 21, 7, 25, 27, 7, 1, 17, 9, 3, 5, 26, 28, 0, 11, 5, 7, 1, 18, 13, 1, 11, 25, 0, 15, 4, 13, 13, 28, 27, 8, 29, 13, 24, 7, 27, 13, 14, 29, 20, 8, 11, 25, 20, 6, 14, 16, 7, 6, 19, 17, 17, 19, 27, 13, 12, 21, 27, 23, 3, 14, 0, 10, 6, 11, 17, 21, 15, 20, 23, 10, 17, 18, 2, 29, 14, 29, 25, 2, 28, 14, 8, 16, 18, 21, 26, 9, 23, 18, 14, 20, 17, 2, 27, 22, 2, 27, 23, 7, 24, 24, 20, 29, 29, 8, 26, 4, 3, 11, 22, 26, 0, 21, 17, 10, 25, 10, 7, 26, 4, 22, 23, 15, 17, 20, 18, 20, 29, 26, 22, 5, 24, 14, 15, 5, 19, 17, 16, 21, 21, 25, 7, 18, 22, 18, 11, 14, 13, 18, 6, 27, 23, 20, 18, 18, 13, 23, 29, 18, 11, 14, 15, 19, 8, 4, 25, 1, 11, 20, 2, 22, 13, 23, 24, 19, 10, 4, 15, 0, 5, 19, 17, 21, 19, 13, 26, 12, 29, 28, 0, 7, 26, 0, 7, 12, 17, 13, 17, 6, 0, 5, 5, 13, 13, 21, 15, 18, 15, 5, 1, 13, 8, 9, 20, 26, 26, 27, 19, 23, 3, 9, 22, 24, 19, 13, 11, 2, 19, 28, 3, 13, 5, 29, 29, 26, 20, 9, 29, 5, 11, 25, 5, 24, 11, 22, 3, 12, 0, 25, 8, 13, 4, 17, 27, 7, 19, 8, 14, 27, 6, 18, 4, 5, 22, 22, 20, 27, 2, 20, 15, 22, 9, 0, 29, 24, 25, 22, 26, 14, 22, 1, 13, 4, 26, 17, 0, 11, 23, 11, 25, 7, 17, 4, 12, 17, 15, 19, 22, 21, 29, 15, 5, 1, 2, 19, 23, 26, 29, 15, 27, 23, 26, 0, 5, 14, 1, 26, 24, 29, 1, 23, 15, 26, 10, 1, 8, 25, 21, 22, 11, 22, 1, 21, 19, 11, 20, 25, 13, 10, 9, 14, 15, 7, 19, 7, 20, 28, 19, 24, 1, 15, 15, 7, 15, 4, 21, 5, 27, 13, 6, 25, 23, 28, 27, 20, 27, 19, 5, 16, 14, 12, 19, 0, 26, 24, 15, 20, 20, 25, 17, 7, 26, 7, 11, 6, 27, 29, 17, 12, 21, 13, 18, 18, 17, 9, 14, 22, 7, 6, 19, 29, 6, 8, 5, 27, 7, 24, 21, 21, 6, 20, 14, 5, 21, 16, 19, 27, 27, 14, 27, 6, 8, 6, 16, 8, 24, 23, 2, 1, 0, 17, 14, 24, 17, 29, 7, 7, 1, 24, 27, 23, 26, 7, 7, 26, 8, 13, 6, 18, 24, 18, 29, 1, 18, 29, 18, 8, 16, 8, 8, 0, 15, 14, 6, 12, 6, 18, 14, 19, 14, 29, 27, 29, 21, 17, 8, 21, 1, 17, 18, 8, 8, 10, 17, 4, 24, 13, 6, 9, 1, 18, 11, 14, 27, 25, 26, 10, 29, 17, 26, 16, 29, 8, 5, 10, 6, 20, 21, 16, 6, 25, 15, 29, 29, 8, 28, 29, 21, 8, 8, 15, 9, 0, 23, 24, 18, 3, 18, 15, 5, 11, 25, 18, 15, 27, 21, 28, 29, 1, 3, 19, 5, 25, 18, 23, 26, 26, 14, 5, 23, 7, 9, 17, 21, 5, 11, 2, 23, 26, 21, 22, 18, 5, 4, 18, 19, 27, 26, 24, 0, 0, 24, 16, 14, 28, 25, 12, 25, 10, 6, 22, 24, 19, 5, 23, 12, 23, 17, 23, 11, 18, 0, 28, 8, 17, 14, 25, 11, 18, 6, 13, 15, 17, 5, 7, 8, 13, 9, 11, 11, 6, 21, 18, 12, 8, 24, 28, 23, 27, 5, 26, 3, 17, 5, 10, 15, 20, 9, 6, 5, 6, 21, 29, 0, 13, 5, 15, 21, 22, 21, 8, 11, 23, 5, 10, 18, 4, 22, 5, 9, 5, 18, 17, 5, 21, 26, 5, 21, 14, 5, 28, 28, 27, 7, 9, 12, 4, 23, 5, 2, 26, 28, 16, 21, 25, 17, 1, 14, 3, 5, 5, 20, 22, 21, 3, 23, 20, 17, 13, 20, 26, 22, 3, 1, 23, 11, 11, 0, 26, 2, 24, 3, 5, 21, 11, 15, 7, 21, 8, 17, 27, 11, 20, 18, 2, 5, 29, 0, 7, 26, 7, 15, 8, 26, 21, 19, 7, 21, 24, 14, 19, 29, 17, 5, 12, 6, 16, 16, 22, 28, 27, 5, 7, 23, 4, 0, 15, 28, 0, 22, 15, 23, 27, 19, 27, 0, 11, 19, 19, 19, 5, 12, 9, 17, 12, 26, 5, 22, 26, 5, 16, 0, 22, 1, 7, 28, 27, 11, 7, 21, 25, 13, 17, 8, 25, 3, 17, 5, 13, 25, 17, 2, 5, 26, 24, 23, 11, 26, 9, 24, 20, 8, 11, 7, 11, 19, 7, 17, 9, 6, 26, 18, 5, 8, 7, 17, 5, 14, 5, 19, 13, 6, 26, 26, 10, 21, 28, 17, 12, 20, 23, 4, 27, 17, 19, 0, 29, 18, 21, 29, 20, 1, 20, 29, 25, 7, 22, 22, 21, 20, 16, 15, 7, 17, 18, 1, 22, 6, 20, 26, 23, 15, 23, 18, 16, 21, 22, 8, 15, 7, 11, 24, 29, 18, 6, 21, 24, 1, 1, 27, 14, 14, 19, 4, 13, 26, 19, 7, 25, 0, 26, 13, 20, 27, 4, 13, 2, 6, 21, 13, 17, 8, 14, 5, 22, 8, 11, 28, 27, 27, 27, 14, 19, 18, 17, 2, 23, 9, 16, 28, 17, 26, 14, 22, 28, 23, 21, 17, 5, 3, 10, 18, 0, 19, 10, 15, 26, 23, 8, 18, 24, 2, 11, 16, 29, 2, 7, 25, 4, 15, 9, 23, 24, 7, 24, 15, 8, 22, 11, 11, 26, 7, 22, 8, 13, 11, 9, 5, 10, 26, 19, 19, 5, 13, 2, 0, 6, 25, 0, 7, 22, 5, 4, 2, 11, 25, 9, 0, 27, 27, 15, 7, 18, 17, 12, 23, 29, 7, 15, 28, 13, 24, 18, 0, 5, 0, 21, 14, 22, 0, 15, 13, 13, 9, 2, 22, 18, 5, 5, 15, 20, 4, 6, 7, 20, 15, 17, 23, 26, 5, 23, 9, 27, 23, 14, 23, 3, 29, 27, 5, 22, 21, 10, 27, 8, 0, 23, 2, 22, 28, 18, 16, 25, 12, 26, 25, 23, 18, 22, 4, 17, 18, 15, 12, 18, 27, 0, 1, 7, 7, 20, 26, 13, 17, 28, 5, 10, 13, 7, 28, 21, 25, 3, 8, 4, 24, 18, 1, 11, 18, 17, 0, 0, 7, 4, 21, 28, 18, 4, 9, 22, 22, 5, 19, 29, 18, 16, 25, 25, 25, 13, 22, 2, 4, 13, 10, 11, 10, 19, 15, 2, 15, 21, 18, 26, 23, 15, 20, 29, 7, 19, 22, 27, 20, 19, 6, 8, 9, 26, 8, 25, 17, 1, 20, 8, 4, 19, 0, 18, 19, 28, 19, 5, 19, 6, 10, 6, 4, 23, 19, 18, 19, 21, 27, 24, 11, 5, 22, 25, 4, 24, 6, 20, 10, 5, 5, 5, 5, 27, 6, 25, 18, 11, 5, 11, 28, 8, 14, 8, 14, 18, 0, 24, 18, 4, 14, 19, 5, 13, 23, 6, 5, 22, 5, 23, 24, 15, 15, 7, 15, 12, 4, 15, 16, 26, 5, 4, 12, 11, 11, 27, 6, 15, 0, 14, 26, 22, 5, 5, 13, 7, 21, 18, 22, 15, 1, 22, 7, 14, 13, 20, 26, 13, 2, 9, 5, 22, 19, 0, 12, 21, 21, 23, 6, 17, 20, 11, 9, 17, 20, 4, 18, 11, 23, 28, 17, 14, 28, 8, 15, 6, 12, 22, 18, 28, 28, 3, 9, 12, 21, 18, 25, 23, 8, 16, 6, 24, 1, 5, 14, 0, 19, 1, 3, 21, 29, 7, 18, 19, 7, 25, 28, 16, 16, 0, 5, 19, 18, 15, 27, 6, 13, 4, 19, 23, 20, 11, 20, 11, 14, 20, 23, 21, 3, 20, 6, 20, 26, 19, 27, 28, 26, 10, 21, 8, 9, 29, 18, 17, 14, 7, 29, 0, 28, 7, 14, 18, 29, 1, 4, 22, 26, 8, 13, 4, 3, 20, 19, 8, 14, 15, 19, 28, 22, 4, 7, 21, 13, 24, 7, 2, 7, 27, 5, 2, 18, 26, 16, 3, 9, 8, 28, 8, 19, 24, 14, 18, 8, 29, 27, 18, 27, 23, 11, 13, 28, 0, 22, 5, 19, 23, 15, 4, 6, 24, 17, 13, 20, 19, 24, 2, 12, 17, 21, 20, 16, 15, 9, 11, 14, 8, 7, 5, 23, 26, 27, 6, 26, 10, 15, 11, 12, 13, 18, 23, 2, 15, 3, 11, 25, 14, 5, 17, 25, 29, 28, 6, 4, 24, 14, 13, 21, 22, 11, 17, 16, 1, 17, 11, 11, 26, 27, 0, 25, 23, 29, 2, 2, 6, 5, 24, 22, 17, 28, 21, 25, 29, 5, 21, 11, 21, 25, 15, 3, 26, 16, 25, 9, 27, 10, 17, 4, 25, 8, 12, 17, 29, 5, 14, 14, 27, 18, 13, 18, 29, 28, 6, 15, 26, 16, 21, 6, 27, 5, 7, 29, 11, 8, 5, 25, 13, 5, 3, 5, 22, 9, 2, 25, 23, 14, 22, 22, 13, 13, 18, 10, 1, 18, 5, 8, 5, 23, 9, 12, 15, 26, 19, 15, 16, 20, 25, 19, 8, 13, 25, 28, 8, 4, 27, 13, 24, 7, 17, 13, 27, 16, 9, 18, 7, 2, 8, 28, 29, 0, 8, 3, 29, 10, 26, 5, 11, 5, 13, 8, 16, 14, 11, 22, 21, 16, 19, 29, 9, 1, 5, 8, 10, 5, 28, 11, 22, 27, 20, 5, 14, 29, 10, 19, 23, 8, 5, 23, 14, 21, 8, 15, 21, 22, 18, 15, 29, 4, 12, 2, 8, 7, 6, 9, 13, 23, 20, 23, 2, 3, 18, 22, 20, 15, 11, 24, 0, 5, 13, 12, 12, 6, 12, 19, 1, 8, 18, 10, 19, 28, 10, 14, 0, 4, 6, 20, 24, 28, 3, 28, 1, 20, 10, 6, 23, 4, 28, 25, 18, 14, 25, 15, 18, 11, 16, 4, 26, 24, 7, 23, 28, 5, 21, 0, 11, 8, 25, 16, 6, 17, 26, 17, 11, 7, 19, 17, 16, 22, 9, 3, 5, 22, 20, 9, 15, 19, 15, 1, 28, 3, 5, 13, 26, 26, 10, 29, 19, 27, 13, 20, 25, 15, 14, 15, 2, 13, 25, 7, 4, 11, 11, 28, 22, 18, 11, 10, 7, 4, 5, 11, 20, 21, 15, 27, 26, 11, 27, 13, 6, 11, 21, 8, 0, 16, 18, 8, 28, 5, 25, 16, 11, 12, 13, 13, 5, 19, 7, 29, 22, 25, 15, 7, 19, 6, 15, 20, 25, 6, 13, 22, 27, 27, 9, 13, 24, 24, 20, 25, 24, 8, 13, 11, 11, 25, 26, 19, 26, 5, 18, 3, 0, 22, 26, 4, 8, 29, 20, 28, 7, 22, 29, 7, 17, 17, 15, 4, 2, 25, 22, 19, 24, 10, 22, 6, 6, 2, 24, 29, 24, 5, 2, 18, 26, 9, 1, 17, 26, 1, 28, 17, 6, 23, 13, 28, 14, 24, 26, 2, 9, 12, 29, 22, 11, 14, 0, 29, 22, 19, 5, 15, 14, 17, 13, 12, 15, 9, 16, 13, 0, 2, 5, 28, 9, 20, 19, 13, 25, 8, 21, 17, 0, 18, 22, 19, 17, 8, 2, 13, 1, 12, 22, 7, 23, 4, 1, 11, 10, 5, 0, 8, 16, 4, 26, 24, 11, 21, 26, 19, 11, 26, 28, 22, 25, 25, 15, 13, 26, 18, 19, 19, 1, 0, 22, 23, 27, 2, 21, 0, 16, 3, 11, 15, 4, 24, 23, 21, 16, 0, 28, 13, 7, 26, 17, 10, 23, 11, 25, 13, 6, 15, 1, 23, 12, 22, 11, 19, 26, 3, 12, 0, 18, 29, 25, 1, 7, 20, 9, 17, 7, 5, 6, 29, 23, 21, 29, 5, 6, 17, 15, 24, 28, 1, 2, 2, 21, 29, 20, 25, 24, 0, 29, 23, 11, 26, 24, 5, 11, 19, 2, 7, 27, 7, 15, 16, 18, 8, 6, 24, 20, 28, 15, 28, 12, 4, 24, 11, 13, 23, 29, 17, 7, 18, 11, 13, 26, 17, 9, 7, 20, 7, 25, 20, 23, 7, 21, 20, 17, 11, 28, 26, 20, 15, 17, 22, 6, 22, 16, 0, 6, 28, 23, 23, 21, 0, 28, 7, 19, 0, 12, 13, 20, 23, 5, 10, 21, 19, 20, 16, 19, 19, 2, 7, 16, 4, 6, 28, 26, 5, 28, 29, 26, 28, 24, 12, 15, 6, 8, 21, 26, 15, 24, 10, 10, 25, 20, 1, 13, 29, 28, 4, 0, 18, 10, 0, 22, 22, 25, 18, 0, 22, 23, 14, 14, 4, 8, 21, 7, 7, 17, 15, 13, 18, 6, 12, 20, 21, 22, 11, 8, 24, 18, 17, 8, 18, 23, 9, 20, 8, 6, 13, 24, 28, 22, 29, 24, 16, 22, 7, 6, 28, 27, 17, 13, 11, 0, 3, 23, 10, 7, 13, 14, 23, 17, 18, 14, 2, 11, 5, 17, 18, 26, 9, 17, 20, 8, 5, 25, 22, 10, 13, 13, 14, 4, 25, 6, 29, 6, 20, 29, 11, 4, 22, 13, 16, 20, 22, 27, 11, 25, 4, 14, 27, 18, 11, 6, 26, 23, 13, 29, 16, 18, 28, 16, 15, 20, 23, 0, 20, 23, 16, 26, 7, 11, 25, 5, 15, 29, 20, 22, 22, 29, 18, 0, 28, 15, 1, 2, 13, 2, 18, 19, 21, 20, 21, 18, 15, 5, 7, 19, 9, 18, 18, 18, 19, 9, 8, 1, 1, 21, 22, 23, 20, 4, 8, 26, 9, 3, 3, 6, 13, 25, 2, 15, 14, 15, 5, 23, 9, 5, 22, 8, 1, 27, 11, 2, 17, 8, 29, 1, 3, 15, 13, 8, 16, 1, 13, 29, 23, 5, 13, 0, 6, 0, 14, 24, 5, 18, 13, 11, 28, 11, 21, 10, 25, 6, 6, 1, 18, 17, 19, 16, 16, 28, 14, 14, 15, 20, 24, 17, 25, 20, 6, 4, 4, 29, 7, 6, 23, 21, 25, 22, 5, 11, 5, 26, 11, 25, 28, 16, 18, 15, 2, 8, 8, 17, 26, 21, 20, 18, 18, 18, 21, 26, 13, 19, 5, 6, 7, 5, 12, 20, 12, 4, 3, 13, 28, 22, 25, 25, 7, 23, 18, 27, 2, 6, 15, 29, 10, 6, 5, 4, 11, 17, 26, 25, 28, 20, 19, 11, 24, 1, 29, 24, 18, 0, 6, 7, 5, 5, 7, 4, 10, 25, 1, 29, 16, 15, 28, 6, 19, 6, 18, 13, 22, 24, 11, 20, 24, 20, 26, 20, 21, 14, 25, 12, 27, 18, 13, 5, 25, 28, 11, 26, 1, 21, 12, 25, 5, 4, 24, 6, 0, 13, 17, 17, 8, 29, 25, 15, 5, 19, 11, 22, 15, 5, 23, 25, 8, 11, 11, 29, 5, 29, 13, 18, 6, 28, 14, 12, 19, 7, 23, 19, 25, 25, 7, 1, 26, 24, 21, 11, 10, 4, 11, 22, 26, 14, 22, 3, 24, 0, 22, 4, 18, 5, 17, 24, 2, 15, 6, 14, 2, 7, 25, 2, 19, 1, 1, 8, 19, 19, 13, 23, 11, 26, 27, 17, 0, 5, 29, 24, 22, 25, 4, 6, 8, 5, 0, 13, 7, 26, 17, 11, 21, 2, 2, 27, 17, 7, 13, 18, 12, 25, 10, 28, 5, 8, 12, 0, 13, 16, 18, 5, 18, 18, 2, 20, 10, 25, 15, 20, 22, 29, 9, 18, 3, 4, 14, 21, 18, 8, 20, 27, 24, 1, 13, 9, 29, 17, 29, 19, 29, 21, 21, 18, 3, 11, 9, 9, 24, 8, 1, 8, 15, 15, 19, 25, 24, 7, 5, 12, 15, 27, 26, 25, 10, 11, 25, 25, 29, 1, 13, 7, 16, 7, 15, 5, 4, 17, 19, 12, 10, 24, 6, 19, 10, 20, 22, 6, 12, 9, 3, 28, 7, 17, 29, 6, 15, 14, 11, 26, 24, 14, 25, 18, 11, 5, 11, 23, 29, 8, 8, 13, 17, 15, 18, 19, 24, 6, 21, 10, 1, 16, 23, 23, 26, 16, 28, 4, 2, 19, 25, 22, 25, 18, 21, 24, 22, 13, 4, 17, 19, 20, 19, 27, 18, 19, 18, 26, 11, 14, 19, 11, 20, 9, 20, 8, 25, 20, 6, 20, 14, 13, 13, 12, 1, 17, 29, 10, 13, 18, 11, 14, 5, 20, 24, 25, 5, 6, 8, 6, 0, 6, 13, 23, 1, 29, 24, 28, 24, 1, 24, 13, 11, 5, 8, 0, 26, 25, 2, 7, 23, 5, 7, 11, 6, 28, 8, 23, 26, 15, 7, 15, 24, 28, 23, 17, 6, 28, 17, 1, 24, 28, 6, 23, 28, 18, 14, 28, 17, 2, 28, 2, 16, 19, 22, 22, 28, 19, 16, 11, 15, 14, 28, 26, 16, 17, 7, 27, 19, 24, 16, 13, 18, 12, 15, 18, 8, 22, 21, 14, 10, 16, 29, 25, 28, 10, 13, 29, 19, 17, 5, 17, 25, 6, 29, 22, 27, 23, 16, 7, 15, 25, 8, 13, 6, 3, 13, 24, 7, 7, 25, 14, 14, 7, 17, 28, 24, 29, 2, 9, 29, 11, 24, 1, 26, 7, 1, 21, 26, 5, 18, 26, 25, 6, 14, 7, 12, 2, 2, 27, 13, 18, 9, 21, 20, 26, 17, 9, 20, 7, 16, 4, 6, 9, 14, 4, 25, 2, 12, 7, 5, 12, 26, 17, 26, 20, 5, 24, 20, 10, 29, 2, 2, 5, 24, 11, 7, 2, 28, 5, 0, 11, 1, 15, 8, 14, 22, 16, 19, 17, 23, 29, 19, 25, 24, 28, 27, 11, 16, 13, 14, 28, 18, 21, 13, 8, 17, 22, 13, 16, 24, 20, 5, 25, 19, 21, 20, 23, 6, 20, 15, 18, 6, 20, 29, 18, 16, 11, 21, 27, 1, 27, 21, 13, 3, 7, 13, 16, 27, 23, 2, 18, 16, 25, 4, 27, 6, 23, 8, 15, 16, 19, 18, 7, 22, 19, 17, 27, 14, 1, 23, 0, 10, 22, 22, 14, 16, 14, 7, 19, 13, 9, 1, 9, 11, 22, 6, 8, 8, 16, 7, 14, 19, 9, 14, 18, 2, 0, 22, 19, 22, 14, 25, 8, 19, 19, 16, 19, 4, 29, 27, 13, 26, 29, 18, 24, 6, 12, 7, 13, 6, 23, 29, 1, 11, 24, 10, 29, 2, 12, 15, 6, 18, 23, 4, 4, 4, 20, 21, 28, 19, 20, 10, 0, 12, 13, 11, 4, 5, 21, 8, 22, 0, 7, 9, 5, 15, 21, 3, 23, 13, 25, 29, 17, 13, 16, 9, 5, 15, 25, 21, 24, 25, 15, 28, 17, 17, 0, 9, 0, 14, 10, 13, 7, 8, 20, 12, 9, 2, 7, 6, 26, 11, 0, 18, 28, 9, 0, 7, 13, 2, 28, 5, 29, 25, 5, 25, 22, 8, 7, 8, 13, 13, 26, 17, 26, 24, 16, 5, 1, 6, 21, 16, 18, 23, 2, 21, 22, 3, 28, 13, 17, 4, 22, 29, 17, 18, 24, 13, 19, 10, 0, 7, 28, 22, 29, 8, 6, 16, 9, 8, 0, 17, 13, 25, 21, 17, 9, 5, 0, 11, 13, 0, 8, 5, 23, 23, 9, 26, 17, 27, 17, 0, 11, 26, 24, 21, 22, 9, 19, 5, 3, 22, 29, 7, 7, 13, 10, 5, 24, 8, 4, 7, 18, 22, 9, 17, 22, 29, 25, 13, 22, 19, 1, 16, 11, 17, 19, 8, 20, 17, 13, 13, 21, 27, 17, 27, 11, 5, 1, 23, 27, 5, 6, 18, 23, 3, 12, 14, 4, 27, 26, 22, 29, 17, 26, 15, 5, 19, 21, 4, 27, 20, 28, 13, 26, 21, 27, 18, 23, 20, 21, 19, 16, 15, 7, 4, 28, 17, 22, 19, 6, 26, 7, 1, 22, 16, 26, 5, 13, 18, 23, 27, 26, 5, 3, 23, 14, 24, 29, 7, 7, 5, 18, 0, 5, 14, 7, 14, 27, 14, 29, 11, 26, 19, 5, 6, 17, 11, 15, 2, 12, 28, 25, 26, 0, 23, 19, 9, 11, 7, 5, 19, 13, 22, 18, 16, 11, 22, 18, 13, 6, 24, 8, 8, 19, 29, 5, 14, 11, 26, 12, 5, 2, 25, 24, 27, 19, 13, 26, 11, 14, 8, 1, 21, 29, 0, 10, 20, 6, 13, 10, 6, 20, 6, 19, 17, 25, 8, 9, 9, 8, 13, 13, 1, 13, 15, 18, 6, 2, 2, 14, 17, 0, 9, 6, 19, 25, 20, 29, 23, 15, 27, 27, 18, 2, 22, 20, 8, 17, 17, 26, 26, 23, 22, 14, 1, 27, 29, 29, 3, 6, 2, 25, 5, 22, 17, 5, 17, 1, 14, 23, 9, 23, 6, 2, 13, 20, 7, 8, 7, 11, 15, 13, 24, 18, 23, 29, 4, 25, 16, 19, 6, 9, 14, 7, 18, 28, 18, 10, 28, 11, 5, 4, 28, 26, 26, 27, 14, 28, 22, 29, 1, 2, 3, 19, 28, 22, 21, 7, 25, 4, 29, 19, 29, 22, 2, 19, 15, 23, 11, 18, 14, 6, 18, 6, 7, 5, 3, 3, 25, 24, 0, 26, 23, 26, 19, 7, 7, 26, 25, 19, 19, 9, 19, 22, 15, 9, 6, 11, 22, 18, 5, 14, 14, 29, 24, 16, 12, 2, 28, 22, 29, 19, 15, 13, 19, 6, 3, 28, 15, 29, 17, 10, 6, 11, 4, 4, 16, 13, 21, 17, 9, 1, 25, 13, 22, 24, 19, 7, 11, 24, 6, 7, 21, 6, 6, 23, 25, 14, 22, 17, 6, 17, 5, 4, 26, 22, 24, 12, 22, 9, 25, 8, 28, 3, 3, 22, 25, 6, 7, 17, 8, 18, 29, 9, 18, 6, 12, 15, 15, 5, 1, 27, 4, 10, 29, 13, 11, 15, 6, 24, 21, 5, 13, 5, 14, 7, 0, 20, 4, 16, 15, 23, 5, 19, 0, 27, 3, 24, 25, 6, 5, 7, 22, 0, 26, 0, 29, 8, 10, 1, 15, 17, 2, 6, 29, 13, 10, 9, 6, 14, 14, 0, 4, 28, 6, 8, 24, 18, 5, 17, 6, 28, 13, 5, 29, 7, 25, 8, 28, 28, 3, 1, 7, 11, 15, 13, 28, 2, 10, 16, 29, 23, 7, 27, 7, 11, 22, 27, 2, 27, 25, 23, 24, 27, 21, 5, 14, 26, 8, 8, 8, 6, 27, 10, 17, 7, 14, 7, 5, 26, 25, 9, 22, 13, 7, 13, 25, 8, 9, 8, 7, 27, 7, 12, 27, 5, 16, 18, 15, 5, 23, 0, 20, 25, 27, 28, 16, 29, 23, 16, 15, 13, 1, 5, 18, 9, 8, 28, 2, 1, 17, 3, 8, 24, 22, 25, 25, 2, 10, 12, 3, 29, 26, 1, 12, 10, 19, 16, 7, 7, 20, 7, 9, 5, 22, 5, 13, 12, 15, 14, 22, 15, 18, 27, 23, 5, 25, 5, 18, 26, 28, 2, 29, 15, 12, 6, 28, 17, 8, 2, 21, 8, 28, 23, 5, 16, 24, 7, 6, 28, 28, 9, 11, 27, 0, 18, 18, 11, 26, 23, 20, 20, 0, 10, 28, 6, 0, 29, 25, 7, 15, 27, 21, 22, 22, 14, 23, 23, 20]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6835\n"
     ]
    }
   ],
   "source": [
    "result = [0 for i in range(6835)]\n",
    "for i in range(6835):\n",
    "    ss = sub.iloc[i]['file_name']\n",
    "    for j in range(6835):\n",
    "        if fl[j] == ss:\n",
    "            result[i] = y_pred[j]\n",
    "            cnt = cnt+1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 22, 6, 22, 25, 22, 14, 16, 26, 26]\n"
     ]
    }
   ],
   "source": [
    "print(result[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = []\n",
    "for i in range(len(result)):\n",
    "    result1.append(filename_list[result[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes', 'stop', 'five', 'stop', 'two', 'stop', 'no', 'on', 'up', 'up']\n"
     ]
    }
   ],
   "source": [
    "print(result1[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'file_name':sub['file_name'],'label':result1})\n",
    "now = time.strftime(\"%Y%m%d_%H%M%S\",time.localtime(time.time())) \n",
    "fname=\"submit_\"+now+r\".csv\"    \n",
    "df.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileHandle = open ( 'traindata_v2.txt', 'wb+' ) \n",
    "pickle.dump(X_train_c, fileHandle) \n",
    "fileHandle.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileHandle = open ( 'ydata_v2.txt', 'wb+' ) \n",
    "pickle.dump(y1_train_c, fileHandle) \n",
    "fileHandle.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileHandle = open ( 'testdata_v2.txt', 'wb+' ) \n",
    "pickle.dump(X_test_c, fileHandle) \n",
    "fileHandle.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
